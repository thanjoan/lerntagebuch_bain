---
title: "Tag 8 - Nachtrag zu Metadaten und Schnittstellen // Suchmaschinen und Discovery-Systeme, Teil 1"
date: 2020-11-27
---

Tag 8 begann mit einem Nachtrag zum Thema Metadaten modellieren, bevor wir dann ins Thema Suchmaschinen und Discovery-Systeme einstiegen und uns mit VuFind und Solr befassten.


## Nachtrag Metadaten und Schnittstellen
Zunächst ein Input zur sehr wichtigen Validierung von Daten. Anschliessend folgen weitere Tools zur Metadatentransormation, ein Ausflug in die Nutzung von JSON-APIs, ein Exkurs zu ScrAPIr und zu LIDO.


### Validierung von XML
Das Validieren ist ein sehr wichtiger Schritt. Darum soll hier festgehalten werden, wie das gemacht werden kann. Zum Validieren der XML-Daten werden diese mit einem Schema abgeglichen. Dieses Schema wird auf der [Webseite der Library of Congress](http://www.loc.gov/standards/marcxml/) zur Verfügung gestellt:

![Screenshot Webseite Library of Congress](https://pad.gwdg.de/uploads/upload_df5eccd1afebd4b2add1e34f7ae2708a.png)

Mit so einem Schema werden Regeln festgelegt, dabei werden sowohl Form wie Inhalte festgelegt und es kann entsprechend beides validiert werden.

Das Vorgehen:

1. Die Daten aus dem OpenRefine als XML exportieren; dazu als heruntergeladene Datei die Dateiendung in .xml ändern, weil es aus OpenRefine heraus als .txt daherkommt.
2. Das Schema herunterladen, in den entsprechenden Ordner, darum lautet der erste Befehl `cd Downloads` (wenn es im Downloadordner zu liegen kommen soll).
3. Mit dem Programm `xmllint` validieren (dieses ist unter Ubuntu bereits vorinstalliert).

Für die Schritte zwei und drei werden die folgenden Befehle eingegeben. Besser statt `*xml` zu schreiben, ist es den konkreten Dateinamen, welchen man validiern möchte, einzugeben, weil `*xml` geht über alle xml-Dateien.

![Code zum validieren](https://pad.gwdg.de/uploads/upload_a7c4663a7b042b22b0d8419bd2b6fbf9.png)

<small>Quelle: [Das gemeinsame Codi](https://pad.gwdg.de/ywogyRNTQ_CTg9PvrQywsQ?view).</small>

Anschliessend zeigt es im Terminal die Fehler an, im Abgleich mit der geöffneten Datei im Texteditor lassen sich die Fehler dann eruieren.
Auf folgendem Bild ist zu sehen, wie dies im Terminal aussieht. Zu sehen sind alle eingegebenen Befehle und dass die Daten alle validiert, d.h. frei von Fehlern sind:

![Screenshot Terminal Validierung](https://pad.gwdg.de/uploads/upload_5137cf49a403d9b3fc724845cca0d205.png)


### Weitere Tools zur Metadatentransformation
Neben OpenRefine gibt es noch andere Tools. OpenRefine hat dabei einige Vorteile, wie beispielsweise die grafische Oberfläche, was die Arbeit damit erleichtert. Zudem eignet sich OpenRefine sehr gut für die Datenanreicherung (Reconciliation).

Die Wahl der Software hängt ab vom Metadatenformat und was damit gemacht werden soll. Ein weiteres Kriterium, gerade in der Praxis, ist die Programmiersprache. Denn da eine grafische Oberfläche nicht immer möglich ist, ist es am effizientesten mit einem Tool zu arbeiten, wo man die Sprache kennt.

So eignet sich für Pearl [Catmandu](https://librecat.org/) und für Java [Metafacture](https://github.com/metafacture/metafacture-core). [MarcEdit](https://marcedit.reeset.net/) eignet sich – wie bereits im Kurs gesehen – für MARC21. Für Python gibt es nicht eine vollumfängliche Lösung, aber für MARC21 Daten eignet sich z.B. [pymarc](https://pymarc.readthedocs.io/en/latest/).



