---
title: "Tag 7 - Metadaten modellieren und Schnittstellen nutzen, Teil 2"
date: 2020-11-20
---

Heute, im zweiten Teil zu Metadaten und Schnittstellen, steht das Modellieren der Metadaten im Vordergrund: Mittels OpenRefine schreiben wir MARCXML. 

Als Ausgangslage verwenden wir die .csv-Daten aus den Materialen von der [Library Carpentry zu OpenRefine](https://librarycarpentry.org/lc-open-refine/).

Das Schaubild wird somit um den Strang um OpenRefine erweitert:

![Erweitertes Schaubild mit OpenRefine](https://pad.gwdg.de/uploads/upload_45b0a76cb410227949e3b9d8eeac44a6.png)


Entsprechend haben wir dann für den morgigen [Tag 8](https://thanjoan.github.io/lerntagebuch_bain/2020/11/27/tag-8.html) aus vier verschiedenen Systemen Daten im selben Format vorliegen, welche wir dann mit VuFind indexieren.

Der heutige Tag steht aber steht voll und ganz im Zeichen von [OpenRefine](https://openrefine.org/). Und ich bin froh, hat es heute mit der Installation funktioniert und ich somit wieder ganz dabei:

![Benutzeroberfäche OpenRefine](https://pad.gwdg.de/uploads/upload_2b34909271b02325d43d348990dcbd6f.png)


Doch bevor es an die praktischen Übungen geht: Was ist OpenRefine?


## OpenRefine 
OpenRefine, eine Open-Source-Software, beschreibt sich als «powerful tool for working with messy data: cleaning it; transforming it from one format into another; and extendig it with web services and external data» ([OpenRefine.org](https://openrefine.org/)).
Mit OpenRefine können Datan analysiert, bereinigt, konvertiert (modelliert) und angereichert werden. OpenRefine hat eine grafische Oberfläche und basiert stark auf Tabellen. Installiert wird OpenRefine lokal auf dem Computer (weswegen die Daten auch bei einem selbst bleiben – ein wichtiger Aspekt bezüglich Datensicherheit), und anschliessend im Browser ausgeführt (localhost:3333). Es ist aber auch möglich OpenRefine auf einem Server laufen zu lassen, dabei muss jedoch vorsichtig gearbeitet werden und man muss sich absprechen, weil OpenRefine keine Nutzerverwaltung hat.

Eingesetzt wird OpenRefine in erster Linie für die Fehlerbereinigung und Vereinheitlichung (Normalisierung) von Daten. Das Programm wird aber auch eingesetzt für die Datentransformation, den Datentransfer (z.B. aus einem Bibliothekssystem in Wikidata transferieren), Daten anreichern mit anderen Datensets und vieles mehr.

Angewandt wird OpenRefine vor allem in Bibliotheken, aber auch in anderen Bereichen: Archiv, zu Forschungszwecken, Bioinformatik, Datenjournalismus und andere. Diese verschiedenen Anwendungsfelder haben dazu geführt, dass OpenRefine auch über Funktionen verfügt, die allgemeiner und breiter angelegt sind und nicht so begrenzt sind auf nur einen Bereich (z.B. Bibliothek), dies eröffnet dann auch mehr Möglichkeiten für die Anwendung.

Dies widerspiegelt sich auch an den von OpenRefine unterstützten Formaten, welche umfangreicher und weniger spezifisch sind. Da die Software, wie oben bereits angesprochen, auf Tabellen basiert, ist es nicht erstaunlich, dass sich tabellarische Daten (CSV, TSV, XLS, XSLX, TXT) besonders gut verarbeiten lassen. Aber auch ein XML wie MARCXML oder JSON geht. Entsprechend ist eine spezifische Analyse für z.B. MARC21 und die Marc-Felder so nicht möglich, hierzu empfiehlt sich dann eben eher eine Software, die spezifischer ist und mit Metadatenstandards auch entsprechend umgehen kann.

Nach den misslungenen Erfahrungen des letzten Tages zu Metadaten, stieg ich doch recht bedrückt in diesen Tag mit OpenRefine, auch der Blick in die Library Carpentry machte mir nicht gerade Mut. Doch dann habe ich auf histHub eine spannende Anwendung von OpenRefine gefunden: histHub hat 2017 in einem Projekt die Metadaten zu Fotografien von Annemarie Schwarzenbach mit OpenRefine bearbeitet, um die 3000 Fotografien wurden auch auf Wikimedia Commoms gestellt (mehr Infos dazu [hier bei histHub](https://histhub.ch/annemarie-schwarzenbach/)). Dadurch fand ich wieder etwas Motivation und mir erschloss sich der Sinn des Ganzen und ich begann OpenRefine recht sympathisch und nützlich zu empfinden – eine Software welche zudem auch recht viel kann.   
Auf histHub fand ich dann zudem einige [Beiträge und Tutorials zu OpenRefine](https://histhub.ch/histhub-lab-tutorials-zu-openrefine), die für mich recht hilfreich waren.

## Übung: CSV nach MARCXML mit OpenRefine
Mittels der Funktion *Templating Export* soll MARCXML erstellt werden. Dieser Templating Export dient dazu, die Formate zu erstellen, welche OpenRefine nicht von sich aus erstellt – man schreibt hier also eigentlich selbst von Hand.  
In das sich öffnende Fenster *Templating Export* haben wir zuerst das bereits ausgefüllte im JSON-Format gelöscht und neu befüllt mit den Angaben für die Vorlage aus dem gemeinsamen Codi-Dokument. Das sah dann so aus:


![Templating Export Fenster in OpenRefine](https://pad.gwdg.de/uploads/upload_c7895b623bed5121ef7e69c3c8e74047.png)

Im Fenster *Templating Export* muss die linke Spalte muss befüllt werden, in der rechten Spalte erscheint automatisch eine Vorschau des Geschriebenen. *Prefix* braucht es immer am Anfang, mit *Suffix* wird es geschlossen. Alles was im *Row Template* geschrieben wird, wird für jede Zeile bzw. Datensatz einmal ausgegeben. Im *Row Template* muss mit [GREL-Befehlen](https://histhub.ch/grel/) geschrieben werden. GREL-Befehle stehen immer in zwei geschweiften Klammern. Und so lässt sich ein XML schreiben. Mittels des Export-Buttons kann man das dann exportieren für alle Datensätze (weil hier ist ja erstmal nur eine Vorschau zu sehen). Dies schaut dann, geöffnet im Texteditor so aus:

![Screenshot Texteditor Export Datensatz](https://pad.gwdg.de/uploads/upload_52d516a0ca0d25bfdf58b7c59b655df9.png)

**In einer ersten Übung** («Reverse Engineering») sollten wir herausfinden, was das *Row Template* leistet: Ausgangslage und Ergebnis vergleichen und so herausfinden, welche Transformationen geschehen. **In der zweiten Übung** galt es das Template zu ergänzen, d.h. MARC21 selbst von Hand modellieren. Da muss ich gestehen, das fiel mir überhaupt nicht leicht, alleine zuhause. Sollte ich OpenRefine jemals brauchen wollen oder müssen, so werde ich mir das alles, inkl. die Felder von MARC21, nochmals ganz gründlich ansehen müssen. Einen groben Einblick habe ich nun, aber die Anwendung fällt mir noch schwer.

**Eine Anmerkung zu leeren Tabellenzellen:** Es ist wichtig, auf leere Tabellenzellen zu achten. Dafür braucht es Regeln, weil wenn entweder «null» (technisches Null) oder auch gar nichts drin steht (z.B. ist kein Titel eingefügt), so ist das unschön. Besser ist es, wenn das entsprechende Feld jeweils gar nicht angezeigt wird. Dafür gibt es die Funktion `forNonBlank()`.

Geschrieben wird das so:
![Code für forNonBlank](https://pad.gwdg.de/uploads/upload_de2d86c5ca8dfdd96cfec30052c282eb.png)

<small>Quelle: das [gemeinsame Codi](https://pad.gwdg.de/ywogyRNTQ_CTg9PvrQywsQ?view).</small>

Diese Sache mit der Null finde ich sehr spannend und fast schon philosophisch. Null ist nicht gleich Null und Null bedeutet auch nicht immer nichts aber manchmal schon. (Aus Zeitgründen schaffe ich es nicht mehr, hier noch tiefer einzusteigen, möchte jedoch für mein einfach [diesen GitHub-Link](https://github.com/OpenRefine/OpenRefine/issues/1491#issuecomment-366464701festhalten), um dem irgendwann später nachzugehen.)


## Exkurs und zusätzliche Aufgabe – Anreicherung mit lobid-gnd
Diese Aufgabe war für mich sehr schwierig, fiel mir doch schon die Handhabung mit OpenRefine an sich nicht leicht. Aus diesem Grund habe ich mich dazu entschieden, einfach nur den [Zusatzartikel](https://blog.lobid.org/2018/08/27/openrefine.html) zu lesen und gedanklich nachvollziehen zu versuchen.


